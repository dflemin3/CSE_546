{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "David Fleming Oct 2015\n",
    "\n",
    "CSE 546 HW 1 Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Imports\n",
    "import scipy.sparse as sp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2  3]\n",
      " [ 4  5  6  7]\n",
      " [ 8  9 10 11]]\n",
      "\n",
      "(3, 4) (4,)\n",
      "\n",
      "[  6.  22.  38.]\n",
      "\n",
      "[ 12.]\n",
      "\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "####\n",
    "# This is a quick walkthrough to help you understand the operations in scipy.sparse\n",
    "####\n",
    "\n",
    "# construct a sparse array, here we simply construct it from dense array\n",
    "A = np.arange(12).reshape(3,4)\n",
    "print A\n",
    "X = sp.csc_matrix(A)\n",
    "\n",
    "w = np.ones(4)\n",
    "print\n",
    "print X.shape, w.shape\n",
    "\n",
    "#  matrix vector multiplication\n",
    "y = X.dot(w)\n",
    "print\n",
    "print y\n",
    "\n",
    "#\n",
    "# dot product between i-th column of X and g\n",
    "#\n",
    "i = 0\n",
    "g = np.ones(3)\n",
    "# r1 = dot(X[:,i], g), because X takes matrix syntax, we need to do it in this way\n",
    "r1 = X[:,i].T.dot(g)\n",
    "print\n",
    "print r1\n",
    "#\n",
    "# This is how you can get dot(X[:,i], X[:,i]) in csc_matix\n",
    "#\n",
    "r2 = X[:,i].T.dot(X[:,i])[0,0]\n",
    "print\n",
    "print r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_norm_data(n,k,d,sigma=1):\n",
    "    \"\"\"\n",
    "    Generates independent data pairs (x_i,y_i) according to the following model:\n",
    "    \n",
    "    yi = w*_0 + w*_1x_i_1 + w*2 x_i_2 + ... w*k x_i_k + eps_i\n",
    "    \n",
    "    for eps_i = Gaussian noise of the form N(0,sigma^2)\n",
    "    and each element of X (shape N x d) is from N(0,1)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n : int\n",
    "        Number of samples\n",
    "    k : int\n",
    "        k < d number of features for dimensions d\n",
    "    d : int\n",
    "        number of dimensions\n",
    "    sigma : float\n",
    "        Gaussian error standard deviation\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    w : vector\n",
    "        true weight vector\n",
    "    X : n x d matrix\n",
    "        data matrix\n",
    "    y : n x 1 vector\n",
    "    \"\"\"\n",
    "    assert(k < d), \"k < d must hold for k: %lf, d: %lf\" % (k,d)\n",
    "    \n",
    "    #Create w vector\n",
    "    #Let w0 = 0 and create a w∗ by setting the first k elements to ±10 \n",
    "    #(choose any sign pattern) and the remaining elements to 0\n",
    "    w = np.zeros(d)\n",
    "    for i in range(1,k+1):\n",
    "        if i < k/2:\n",
    "            w[i] = 10\n",
    "        else:\n",
    "            w[i] = -10\n",
    "    \n",
    "    #Generate n x d data matrix X for each element from N(0,1)\n",
    "    X = sp.csc_matrix(np.random.randn(n, d))\n",
    "    \n",
    "    #Generate n x 1 array of Gaussian error samples from N(0,sigma^2)\n",
    "    eps = np.random.randn(n)\n",
    "    \n",
    "    #Finally, generate a Gaussian noise vector eps with variance σ^2 and \n",
    "    #form y = Xw* + w*_0 + eps for w*_0 assumed to be 0\n",
    "    y = X.dot(w) + eps\n",
    "        \n",
    "    return w, X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def check_solution(X,y,w_pred,w_0_pred,l):\n",
    "    \"\"\"\n",
    "    See if the computed solution w_pred, w_0_pred for a given lambda l\n",
    "    is correct.  That occurs when:\n",
    "    \n",
    "    test = 2X^T(Xw_pred + w_0_pred - y)\n",
    "    test_j = -lambda*sign(w_pred_j) for each j that is nonzero\n",
    "    Otherwise, each j value should be lesser in magnitude that lambda\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : n x d matrix of data\n",
    "    y : N x 1 vector of response variables\n",
    "    w_pred : predicted d dimensions weight vector\n",
    "    w_0_pred : scalar offset term\n",
    "    l : regularization tuning parameter\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    ans : bool\n",
    "        whether or not the solution passes the test criteria\n",
    "    \"\"\"\n",
    "    eps = 1.0e-8\n",
    "    condition = False\n",
    "    \n",
    "    test = 2.0*X.T*(X.dot(w_pred) + w_0_pred - y)\n",
    "    \n",
    "    #Mask values corresponding to w_pred == 0\n",
    "    mask = np.fabs(w_pred) < eps\n",
    "    mask2 = np.fabs(test[mask]) < l\n",
    "    mask = np.ones(len(w_pred))[mask]\n",
    "            \n",
    "    if np.array_equal(mask2,mask) and np.sum(mask) != len(w_pred):\n",
    "        w_j = test[np.logical_not(mask)]\n",
    "        if np.allclose(w_j,-l*np.sign(w_j),atol=1.0e-10, rtol=1.0e-1) and w_j != []:\n",
    "            condition = True\n",
    "        else:\n",
    "            condition = False\n",
    "    else:\n",
    "        condition = False\n",
    "    \n",
    "    return condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_max_lambda(X,y):\n",
    "    \"\"\"\n",
    "    Compute the smallest lambda for which the solution w is entirely zero\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : n x d matrix of data (scipy sparse matrix)\n",
    "    y : n x 1 vector of response variables\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    l : float\n",
    "        Smallest value of lambda for which the solution w is entirely zero\n",
    "    \"\"\"\n",
    "    y_mean = np.mean(y)\n",
    "    arg = X.T.multiply(y - y_mean)\n",
    "    return 2.0*np.linalg.norm(arg,ord=np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def naive_lasso(X,y,l=10,w=-999,w_0=-999):\n",
    "    \"\"\"\n",
    "    Implimentation of the naive (un-optimized) lasso regression \n",
    "    algorithm.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : n x d matrix of data\n",
    "    X_i : the ith row of X\n",
    "    y : N x 1 vector of response variables\n",
    "    w : d dimensions weight vector (optional)\n",
    "    w_0 : scalar offset term (optional)\n",
    "    l : regularization tuning parameter\n",
    "    \n",
    "    All matrices X assumed to be sparse and of the form given by \n",
    "    scipy.sparse.csc matrix\n",
    "    \n",
    "    Algorithm 1: Coordinate Descent Algorithm for Lasso\n",
    "    \n",
    "    while not converged do:\n",
    "        w_0 <- sum_i=1_N[y_i - sum_j[w_j X_ij]]/N\n",
    "        for(k [1,d]) do:\n",
    "            a_k <- 2 * sum_i=1_N[X_ik ^2]\n",
    "            c_k <- 2 * sum_i=1_N[X_ik (y_i - (w_0 + sum_j!=k[w_j X_ij]))]\n",
    "            w_k <- (c_k + lambda)/a_k if c_k < -lambda\n",
    "                    0 if c_k is between [-lambda,lambda]\n",
    "                    (c_k - lambda)/a_k if c_k > lambda\n",
    "        end\n",
    "    end\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    w : numpy array\n",
    "        d x 1 weight vector\n",
    "    w_0 : float\n",
    "        offset\n",
    "        \n",
    "    \"\"\"\n",
    "    #Define values\n",
    "    N = y.shape[0]\n",
    "    d = X.shape[1]\n",
    "    \n",
    "    #If no initial conditions, assume Gaussian\n",
    "    if w == -999:\n",
    "        w = np.random.randn(d)\n",
    "    if w_0 == -999:\n",
    "        w_0 = np.random.randn(1)\n",
    "    \n",
    "    #Convergence condition\n",
    "    eps = 1.0e-3\n",
    "    w_old = np.zeros(w.shape)\n",
    "    w_pred = np.copy(w)\n",
    "    \n",
    "    while((w_pred - w_old).dot(w_pred - w_old) > eps):\n",
    "        #Store for convergence test \n",
    "        w_old = np.copy(w_pred)\n",
    "        \n",
    "        #Compute w_0\n",
    "        w_0 = np.sum(y)\n",
    "        w_0 -= X.dot(w_pred).sum()\n",
    "        w_0 /= N\n",
    "            \n",
    "        #Compute a_k: d x 1 summing over columns\n",
    "        a = 2.0*np.asarray((X.power(2).sum(axis=0).T))\n",
    "        c = np.zeros(d)\n",
    "            \n",
    "        for k in range(0,d):\n",
    "            #Compute c_k: d x 1\n",
    "            c_sum = 0.0\n",
    "            for i in range(0,N):\n",
    "                #Select not k columns\n",
    "                ind = [x for x in range(0,d) if x != k]\n",
    "                c_sum += X[i,k]*(y[i] - (X[i,ind].dot(w[ind]) + w_0))\n",
    "            c[k] = 2.0*c_sum\n",
    "            \n",
    "            #Compute w_k\n",
    "            if(c[k] < -l):\n",
    "                w_pred[k] = (c[k] + l)/a[k]\n",
    "            elif(c[k] >= -l and c[k] <= l):\n",
    "                w_pred[k] = 0.0\n",
    "            elif(c[k]  > l):\n",
    "                w_pred[k] = (c[k] - l)/a[k]\n",
    "            else:\n",
    "                print \"Error! Shouldn't ever happen.\"\n",
    "        #end for\n",
    "        #print w_pred\n",
    "    #end while\n",
    "    \n",
    "    #Return as row array\n",
    "    return w_pred, w_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def lasso_reg_path(X,y,w=-999,w_0=-999,scale=0.8,reg_type=\"naive\"):\n",
    "    \"\"\"\n",
    "    Implimentation of the naive (un-optimized) lasso regression \n",
    "    algorithm.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : n x d matrix of data\n",
    "    y : n x 1 vector of response variables\n",
    "    w : d dimensions weight vector (optional)\n",
    "    w_0 : scalar offset term (optional)\n",
    "    scale : by how much lambda l decreases each run\n",
    "    reg_type : str\n",
    "        naive = use slow naive lasso\n",
    "        quick = use optimized lasso\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    All matrices assumed to be sparse and of the form given by \n",
    "    scipy.sparse.csc matrix\n",
    "    \n",
    "    \"\"\"\n",
    "    #Choose upper bound for lambda, initial conditions\n",
    "    l = compute_max_lambda(X,y)*scale\n",
    "    \n",
    "    #If no initial conditions, assume Gaussian\n",
    "    if w == -999:\n",
    "        w = np.random.randn(d)\n",
    "    if w_0 == -999:\n",
    "        w_0 = np.random.randn(1)\n",
    "    \n",
    "    w_pred = np.copy(w)\n",
    "    w_0_pred = w_0\n",
    "        \n",
    "    #If solution isn't converged, keep going\n",
    "    while(l > 1):\n",
    "        w_pred, w_0_pred = naive_lasso(X,y,l=l,w=w_pred,w_0=w_0_pred)        \n",
    "        \n",
    "        #If solution is sufficiently good, return it\n",
    "        if check_solution(X,y,w_pred=w_pred,w_0_pred=w_0_pred,l=l):\n",
    "            return w_pred, w_0_pred, l\n",
    "        \n",
    "        #Decrease scale for next iteration\n",
    "        l *= scale\n",
    "    \n",
    "    return w_pred, w_0_pred, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def quick_lasso(X,y,l=10,w=-999,w_0=-999):\n",
    "    \"\"\"\n",
    "    Implimentation of the naive (un-optimized) lasso regression \n",
    "    algorithm.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : n x d matrix of data\n",
    "    X_i : the ith row of X\n",
    "    y : N x 1 vector of response variables\n",
    "    w : d dimensions weight vector (optional)\n",
    "    w_0 : scalar offset term (optional)\n",
    "    l : regularization tuning parameter\n",
    "    \n",
    "    All matrices X assumed to be sparse and of the form given by \n",
    "    scipy.sparse.csc matrix\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    w : numpy array\n",
    "        d x 1 weight vector\n",
    "    w_0 : float\n",
    "        offset   \n",
    "    \"\"\"\n",
    "    #Define values\n",
    "    n = y.shape[0]\n",
    "    d = X.shape[1]\n",
    "    \n",
    "    #Convergence condition\n",
    "    eps = 1.0e-3\n",
    "    \n",
    "    #If no initial conditions, assume Gaussian\n",
    "    if w == -999:\n",
    "        w = np.random.randn(d)\n",
    "    if w_0 == -999:\n",
    "        w_0 = np.random.randn(1)\n",
    "    \n",
    "    w_pred = np.copy(w).reshape(d,1) # d x 1\n",
    "    w_old = np.zeros(w_pred.shape) # d x 1\n",
    "    y = y.reshape(n,1) # n x 1\n",
    "    \n",
    "    while((w_pred - w_old).dot((w_pred - w_old).T)[0][0] > eps):\n",
    "        if np.fabs(w_0) > 1.0e10 or np.fabs(w_0) < 1.0e-8:\n",
    "            print(\"w_0 too large\")\n",
    "            break\n",
    "        \n",
    "        #Store for convergence test \n",
    "        w_old = np.copy(w_pred)\n",
    "        \n",
    "        #Compute y_hat (n x 1) to avoid numerical drift\n",
    "        y_hat = X.dot(w_pred) + w_0        \n",
    "            \n",
    "        #Compute w_0 via rule from 6.1.1\n",
    "        w_0 = np.sum(y - np.sum(y_hat))/(n*(1-n))\n",
    "            \n",
    "        #Update y_hat via 6.1.5\n",
    "        y_hat = X.dot(w_pred) + w_0\n",
    "            \n",
    "        #Compute a_k: d x 1 summing over columns\n",
    "        a = 2.0*np.asarray((X.power(2).sum(axis=0).T))\n",
    "        c = np.zeros(d).reshape(d,1)\n",
    "          \n",
    "        for k in range(0,d):\n",
    "    \n",
    "            alpha = np.zeros((d,d))\n",
    "            alpha[k,k] = 1\n",
    "            alpha = X.dot(alpha.dot(w_pred))\n",
    "                                        \n",
    "            #Compute c_k: d x 1\n",
    "            #c[k] = 2.0*X[:,k].T.dot((y-y_hat-alpha))\n",
    "            #Compute c_k: d x 1\n",
    "            c_sum = 0.0\n",
    "            for i in range(0,N):\n",
    "                #Select not k columns\n",
    "                ind = [x for x in range(0,d) if x != k]\n",
    "                c_sum += X[i,k]*(y[i] - (X[i,ind].dot(w[ind]) + w_0))\n",
    "            c[k] = 2.0*c_sum \n",
    "                             \n",
    "            #Compute w_k\n",
    "            if(c[k] < -l):\n",
    "                w_pred[k] = (c[k] + l)/a[k]\n",
    "            elif(c[k] >= -l and c[k] <= l):\n",
    "                w_pred[k] = 0.0\n",
    "            elif(c[k]  > l):\n",
    "                w_pred[k] = (c[k] - l)/a[k]\n",
    "            else:\n",
    "                print \"Error! Shouldn't ever happen.\"\n",
    "                break\n",
    "                \n",
    "            alpha = np.zeros((d,d))\n",
    "            alpha[k,k] = 1\n",
    "            alpha = X.dot(alpha.dot(w_pred))\n",
    "\n",
    "            y_hat = y_hat + ((X).dot(w_pred)) - alpha\n",
    "        #end for\n",
    "    #end while\n",
    "    \n",
    "    #Return as row array\n",
    "    return w_pred.T, w_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.  10. -10. -10. -10. -10.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.]\n",
      "[[  1.91400787   7.48356246  -8.76105093  -7.44131675  -9.04604575\n",
      "  -10.31696602   2.0363051   -4.21799822   0.78658413   0.           2.73886106\n",
      "    0.94306798   1.58023382  -3.57345522   2.75489693   0.58564417\n",
      "    2.12731239   2.28438591  -0.87865145   3.07182718]]\n",
      "\n",
      "0.793550780336\n"
     ]
    }
   ],
   "source": [
    "N = 100\n",
    "k = 5\n",
    "d = 20\n",
    "#w, X, y = generate_norm_data(N,k,d)\n",
    "\n",
    "w_pred, w_0_pred = quick_lasso(X,y,l=5)\n",
    "\n",
    "print w\n",
    "print w_pred\n",
    "#print l\n",
    "print\n",
    "\n",
    "SSres = np.sum(np.power(w_pred-w,2))\n",
    "w_bar = np.mean(w)\n",
    "SStot = np.sum(np.power(w_pred-w_bar,2))\n",
    "print(1.0 - (SSres/SStot))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "N = 500\n",
    "k = 5\n",
    "d = 75\n",
    "#l = 2750\n",
    "w, X, y = generate_norm_data(N,k,d)\n",
    "\n",
    "#print(w.shape)\n",
    "#print\n",
    "#print(X.shape)\n",
    "#print\n",
    "#print(y.shape)\n",
    "\n",
    "l = compute_max_lambda(X,y)\n",
    "\n",
    "print\n",
    "print l\n",
    "print\n",
    "\n",
    "w_pred, w_0_pred = naive_lasso(X,y,w=w,w_0=1,l=l/100.)\n",
    "#w_test = -999\n",
    "#w_0_test = -999\n",
    "#w_pred, w_0_pred, l = lasso_reg_path(X,y,w=w_test,w_0=w_0_test,scale=0.9,reg_type=\"naive\")\n",
    "\n",
    "#print w\n",
    "print w\n",
    "print w_pred\n",
    "print\n",
    "\n",
    "SSres = np.sum(np.power(w_pred-w,2))\n",
    "w_bar = np.mean(w)\n",
    "SStot = np.sum(np.power(w_pred-w_bar,2))\n",
    "print(1.0 - (SSres/SStot))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import scipy.io as io\n",
    "import scipy.sparse as sparse\n",
    "import os\n",
    "\n",
    "os.chdir(\"/Users/dflemin3/Desktop/CSE_546/HW1/hw1-data\")\n",
    "\n",
    "# Load a text file of integers:\n",
    "y = np.loadtxt(\"upvote_labels.txt\", dtype=np.int)\n",
    "\n",
    "# Load a text file of strings:\n",
    "featureNames = open(\"upvote_features.txt\").read().splitlines()\n",
    "\n",
    "# Load a csv of floats:\n",
    "A = np.genfromtxt(\"upvote_data.csv\", delimiter=\",\")\n",
    "\n",
    "# Load a matrix market matrix, convert it to csc format:\n",
    "#B = io.mmread(\"star_data.mtx\").tocsc()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "A = sparse.csc_matrix(A)\n",
    "print A.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "w_pred, w_0_pred = naive_lasso(X=A[:3000,:],y=y[:3000],w=-999,w_0=-999,l=10000)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#print w_pred\n",
    "print w_0_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
