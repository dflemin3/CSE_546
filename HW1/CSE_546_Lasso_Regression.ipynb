{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "David Fleming Oct 2015\n",
    "\n",
    "CSE 546 HW 1 Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Imports\n",
    "import scipy.sparse as sp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2  3]\n",
      " [ 4  5  6  7]\n",
      " [ 8  9 10 11]]\n",
      "\n",
      "(3, 4) (4,)\n",
      "\n",
      "[  6.  22.  38.]\n",
      "\n",
      "[ 12.]\n",
      "\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "####\n",
    "# This is a quick walkthrough to help you understand the operations in scipy.sparse\n",
    "####\n",
    "\n",
    "# construct a sparse array, here we simply construct it from dense array\n",
    "A = np.arange(12).reshape(3,4)\n",
    "print A\n",
    "X = sp.csc_matrix(A)\n",
    "\n",
    "w = np.ones(4)\n",
    "print\n",
    "print X.shape, w.shape\n",
    "\n",
    "#  matrix vector multiplication\n",
    "y = X.dot(w)\n",
    "print\n",
    "print y\n",
    "\n",
    "#\n",
    "# dot product between i-th column of X and g\n",
    "#\n",
    "i = 0\n",
    "g = np.ones(3)\n",
    "# r1 = dot(X[:,i], g), because X takes matrix syntax, we need to do it in this way\n",
    "r1 = X[:,i].T.dot(g)\n",
    "print\n",
    "print r1\n",
    "#\n",
    "# This is how you can get dot(X[:,i], X[:,i]) in csc_matix\n",
    "#\n",
    "r2 = X[:,i].T.dot(X[:,i])[0,0]\n",
    "print\n",
    "print r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_norm_data(n,k,d,sigma=1):\n",
    "    \"\"\"\n",
    "    Generates independent data pairs (x_i,y_i) according to the following model:\n",
    "    \n",
    "    yi = w*_0 + w*_1x_i_1 + w*2 x_i_2 + ... w*k x_i_k + eps_i\n",
    "    \n",
    "    for eps_i = Gaussian noise of the form N(0,sigma^2)\n",
    "    and each element of X (shape N x d) is from N(0,1)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n : int\n",
    "        Number of samples\n",
    "    k : int\n",
    "        k < d number of features for dimensions d\n",
    "    d : int\n",
    "        number of dimensions\n",
    "    sigma : float\n",
    "        Gaussian error standard deviation\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    w : vector\n",
    "        true weight vector\n",
    "    X : n x d matrix\n",
    "        data matrix\n",
    "    y : n x 1 vector\n",
    "    \"\"\"\n",
    "    assert(k < d), \"k < d must hold for k: %lf, d: %lf\" % (k,d)\n",
    "    \n",
    "    #Create w vector\n",
    "    #Let w0 = 0 and create a w∗ by setting the first k elements to ±10 \n",
    "    #(choose any sign pattern) and the remaining elements to 0\n",
    "    w = np.zeros(d)\n",
    "    for i in range(1,k+1):\n",
    "        if i < k/2:\n",
    "            w[i] = 10\n",
    "        else:\n",
    "            w[i] = -10\n",
    "    \n",
    "    #Generate n x d data matrix X for each element from N(0,1)\n",
    "    X = sp.csc_matrix(np.random.randn(n, d))\n",
    "    \n",
    "    #Generate n x 1 array of Gaussian error samples from N(0,sigma^2)\n",
    "    eps = np.random.randn(n)\n",
    "    \n",
    "    #Finally, generate a Gaussian noise vector eps with variance σ^2 and \n",
    "    #form y = Xw* + w*_0 + eps for w*_0 assumed to be 0\n",
    "    y = X.dot(w) + eps\n",
    "        \n",
    "    return w, X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def naive_lasso(X,y,l=10,w=None,w_0=None):\n",
    "    \"\"\"\n",
    "    Implimentation of the naive (un-optimized) lasso regression \n",
    "    algorithm.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : n x d matrix of data\n",
    "    X_i : the ith row of X\n",
    "    y : N x 1 vector of response variables\n",
    "    w : d dimensions weight vector (optional)\n",
    "    w_0 : scalar offset term (optional)\n",
    "    l : regularization tuning parameter\n",
    "    \n",
    "    All matrices assumed to be sparse and of the form given by \n",
    "    scipy.sparse.csc matrix\n",
    "    \n",
    "    Algorithm 1: Coordinate Descent Algorithm for Lasso\n",
    "    \n",
    "    while not converged do:\n",
    "        w_0 <- sum_i=1_N[y_i - sum_j[w_j X_ij]]/N\n",
    "        for(k [1,d]) do:\n",
    "            a_k <- 2 * sum_i=1_N[X_ik ^2]\n",
    "            c_k <- 2 * sum_i=1_N[X_ik (y_i - (w_0 + sum_j!=k[w_j X_ij]))]\n",
    "            w_k <- (c_k + lambda)/a_k if c_k < -lambda\n",
    "                    0 if c_k is between [-lambda,lambda]\n",
    "                    (c_k - lambda)/a_k if c_k > lambda\n",
    "        end\n",
    "    end\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    w : weight vector\n",
    "        numpy array\n",
    "    \"\"\"\n",
    "    #Define values\n",
    "    N = y.shape[0]\n",
    "    d = X.shape[1]\n",
    "        \n",
    "    #Convergence condition\n",
    "    eps = 1.0e-3\n",
    "    w_old = np.zeros(w.shape)\n",
    "    w_pred = np.copy(w)\n",
    "    \n",
    "    while((w_pred - w_old).dot(w_pred - w_old) > eps):\n",
    "        #Store for convergence test \n",
    "        w_old = np.copy(w_pred)\n",
    "        \n",
    "        #Compute w_0\n",
    "        w_0 = np.sum(y)\n",
    "        w_0 -= X.dot(w_pred).sum()\n",
    "        w_0 /= N\n",
    "            \n",
    "        #Compute a_k: d x 1 summing over columns\n",
    "        a = 2.0*np.asarray((X.power(2).sum(axis=0).T))\n",
    "        c = np.zeros(d)\n",
    "            \n",
    "        for k in range(0,d):\n",
    "            #Compute c_k: d x 1\n",
    "            c_sum = 0.0\n",
    "            for i in range(0,N):\n",
    "                #Select not k columns\n",
    "                ind = [x for x in range(0,d) if x != k]\n",
    "                c_sum += X[i,k]*(y[i] - (X[i,ind].dot(w[ind]) + w_0))\n",
    "            c[k] = 2.0*c_sum\n",
    "            \n",
    "            #Compute w_k\n",
    "            if(c[k] < -l):\n",
    "                w_pred[k] = (c[k] + l)/a[k]\n",
    "            elif(c[k] >= -l and c[k] <= l):\n",
    "                w_pred[k] = 0.0\n",
    "            elif(c[k]  > l):\n",
    "                w_pred[k] = (c[k] - l)/a[k]\n",
    "            else:\n",
    "                print \"Error! Shouldn't ever happen.\"\n",
    "        #end for\n",
    "        #print w_pred\n",
    "    #end while\n",
    "    \n",
    "    #Return as row array\n",
    "    return w_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75,)\n",
      "(50, 75)\n",
      "(50,)\n",
      "[  0.  10. -10. -10. -10. -10.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "[ 0.          9.28782921 -9.3502097  -9.5710217  -9.56268361 -9.59121316\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.        ]\n",
      "0.996637455657\n"
     ]
    }
   ],
   "source": [
    "N = 50\n",
    "k = 5\n",
    "d = 75\n",
    "w, X, y = generate_norm_data(N,k,d)\n",
    "\n",
    "print(w.shape)\n",
    "#print\n",
    "print(X.shape)\n",
    "#print\n",
    "print(y.shape)\n",
    "\n",
    "w_pred = naive_lasso(X,y,l=40,w=w)\n",
    "\n",
    "#print w\n",
    "print w\n",
    "print w_pred\n",
    "\n",
    "SSres = np.sum(np.power(w_pred-w,2))\n",
    "w_bar = np.mean(w)\n",
    "SStot = np.sum(np.power(w_pred-w_bar,2))\n",
    "print(1.0 - (SSres/SStot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
