{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "David Fleming Oct 2015\n",
    "\n",
    "CSE 546 HW 1 Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Imports\n",
    "import scipy.sparse as sp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2  3]\n",
      " [ 4  5  6  7]\n",
      " [ 8  9 10 11]]\n",
      "\n",
      "(3, 4) (4,)\n",
      "\n",
      "[  6.  22.  38.]\n",
      "\n",
      "[ 12.]\n",
      "\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "####\n",
    "# This is a quick walkthrough to help you understand the operations in scipy.sparse\n",
    "####\n",
    "\n",
    "# construct a sparse array, here we simply construct it from dense array\n",
    "A = np.arange(12).reshape(3,4)\n",
    "print A\n",
    "X = sp.csc_matrix(A)\n",
    "\n",
    "w = np.ones(4)\n",
    "print\n",
    "print X.shape, w.shape\n",
    "\n",
    "#  matrix vector multiplication\n",
    "y = X.dot(w)\n",
    "print\n",
    "print y\n",
    "\n",
    "#\n",
    "# dot product between i-th column of X and g\n",
    "#\n",
    "i = 0\n",
    "g = np.ones(3)\n",
    "# r1 = dot(X[:,i], g), because X takes matrix syntax, we need to do it in this way\n",
    "r1 = X[:,i].T.dot(g)\n",
    "print\n",
    "print r1\n",
    "#\n",
    "# This is how you can get dot(X[:,i], X[:,i]) in csc_matix\n",
    "#\n",
    "r2 = X[:,i].T.dot(X[:,i])[0,0]\n",
    "print\n",
    "print r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_norm_data(n,k,d,sigma=1):\n",
    "    \"\"\"\n",
    "    Generates independent data pairs (x_i,y_i) according to the following model:\n",
    "    \n",
    "    yi = w*_0 + w*_1x_i_1 + w*2 x_i_2 + ... w*k x_i_k + eps_i\n",
    "    \n",
    "    for eps_i = Gaussian noise of the form N(0,sigma^2)\n",
    "    and each element of X (shape N x d) is from N(0,1)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n : int\n",
    "        Number of samples\n",
    "    k : int\n",
    "        k < d number of features for dimensions d\n",
    "    d : int\n",
    "        number of dimensions\n",
    "    sigma : float\n",
    "        Gaussian error standard deviation\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    w : vector\n",
    "        true weight vector\n",
    "    X : n x d matrix\n",
    "        data matrix\n",
    "    y : n x 1 vector\n",
    "    \"\"\"\n",
    "    assert(k < d), \"k < d must hold for k: %lf, d: %lf\" % (k,d)\n",
    "    \n",
    "    #Create w vector\n",
    "    #Let w0 = 0 and create a w∗ by setting the first k elements to ±10 \n",
    "    #(choose any sign pattern) and the remaining elements to 0\n",
    "    w = np.zeros(d)\n",
    "    for i in range(1,k+1):\n",
    "        if i < k/2:\n",
    "            w[i] = 10\n",
    "        else:\n",
    "            w[i] = -10\n",
    "    \n",
    "    #Generate n x d data matrix X for each element from N(0,1)\n",
    "    X = sp.csc_matrix(np.random.randn(n, d))\n",
    "    \n",
    "    #Generate n x 1 array of Gaussian error samples from N(0,sigma^2)\n",
    "    eps = np.random.randn(n)\n",
    "    \n",
    "    #Finally, generate a Gaussian noise vector eps with variance σ^2 and \n",
    "    #form y = Xw* + w*_0 + eps for w*_0 assumed to be 0\n",
    "    y = X.dot(w) + eps\n",
    "        \n",
    "    return w, X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def check_solution(X,y,w_pred,w_0_pred,l):\n",
    "    \"\"\"\n",
    "    See if the computed solution w_pred, w_0_pred for a given lambda l\n",
    "    is correct.  That occurs when:\n",
    "    \n",
    "    test = 2X^T(Xw_pred + w_0_pred - y)\n",
    "    test_j = -lambda*sign(w_pred_j) for each j that is nonzero\n",
    "    Otherwise, each j value should be lesser in magnitude that lambda\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : n x d matrix of data\n",
    "    y : N x 1 vector of response variables\n",
    "    w_pred : predicted d dimensions weight vector\n",
    "    w_0_pred : scalar offset term\n",
    "    l : regularization tuning parameter\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    ans : bool\n",
    "        whether or not the solution passes the test criteria\n",
    "    \"\"\"\n",
    "    eps = 1.0e-8\n",
    "    condition = False\n",
    "    \n",
    "    test = 2.0*X.T*(X.dot(w_pred) + w_0_pred - y)\n",
    "    \n",
    "    #Mask values corresponding to w_pred == 0\n",
    "    mask = np.fabs(w_pred) < eps\n",
    "    mask2 = np.fabs(test[mask]) < l\n",
    "    mask = np.ones(len(w_pred))[mask]\n",
    "            \n",
    "    if np.array_equal(mask2,mask) and np.sum(mask) != len(w_pred):\n",
    "        w_j = test[np.logical_not(mask)]\n",
    "        if np.allclose(w_j,-l*np.sign(w_j),atol=1.0e-10, rtol=1.0e-1) and w_j != []:\n",
    "            condition = True\n",
    "        else:\n",
    "            condition = False\n",
    "    else:\n",
    "        condition = False\n",
    "    \n",
    "    return condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_max_lambda(X,y):\n",
    "    \"\"\"\n",
    "    Compute the smallest lambda for which the solution w is entirely zero\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : n x d matrix of data (scipy sparse matrix)\n",
    "    y : n x 1 vector of response variables\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    l : float\n",
    "        Smallest value of lambda for which the solution w is entirely zero\n",
    "    \"\"\"\n",
    "    y_mean = np.mean(y)\n",
    "    arg = X.T.multiply(y - y_mean)\n",
    "    return 2.0*np.linalg.norm(arg,ord=np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def naive_lasso(X,y,l=10,w=-999,w_0=-999):\n",
    "    \"\"\"\n",
    "    Implimentation of the naive (un-optimized) lasso regression \n",
    "    algorithm.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : n x d matrix of data\n",
    "    X_i : the ith row of X\n",
    "    y : N x 1 vector of response variables\n",
    "    w : d dimensions weight vector (optional)\n",
    "    w_0 : scalar offset term (optional)\n",
    "    l : regularization tuning parameter\n",
    "    \n",
    "    All matrices X assumed to be sparse and of the form given by \n",
    "    scipy.sparse.csc matrix\n",
    "    \n",
    "    Algorithm 1: Coordinate Descent Algorithm for Lasso\n",
    "    \n",
    "    while not converged do:\n",
    "        w_0 <- sum_i=1_N[y_i - sum_j[w_j X_ij]]/N\n",
    "        for(k [1,d]) do:\n",
    "            a_k <- 2 * sum_i=1_N[X_ik ^2]\n",
    "            c_k <- 2 * sum_i=1_N[X_ik (y_i - (w_0 + sum_j!=k[w_j X_ij]))]\n",
    "            w_k <- (c_k + lambda)/a_k if c_k < -lambda\n",
    "                    0 if c_k is between [-lambda,lambda]\n",
    "                    (c_k - lambda)/a_k if c_k > lambda\n",
    "        end\n",
    "    end\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    w : numpy array\n",
    "        d x 1 weight vector\n",
    "    w_0 : float\n",
    "        offset\n",
    "        \n",
    "    \"\"\"\n",
    "    #Define values\n",
    "    N = y.shape[0]\n",
    "    d = X.shape[1]\n",
    "    y = y.reshape(N,1)\n",
    "    \n",
    "    #If no initial conditions, assume Gaussian\n",
    "    if w == -999:\n",
    "        w = np.random.randn(d)\n",
    "    if w_0 == -999:\n",
    "        w_0 = np.random.randn(1)\n",
    "    \n",
    "    #Convergence condition\n",
    "    eps = 1.0e-3\n",
    "    w_old = np.zeros(w.shape).reshape(d,1)\n",
    "    w_pred = np.copy(w).reshape(d,1)\n",
    "    \n",
    "    while((w_pred - w_old).dot((w_pred - w_old).T)[0][0] > eps):\n",
    "        #Store for convergence test \n",
    "        w_old = np.copy(w_pred)\n",
    "        \n",
    "        #Compute w_0\n",
    "        w_0 = np.sum(y)\n",
    "        w_0 -= X.dot(w_pred).sum()\n",
    "        w_0 /= N\n",
    "            \n",
    "        #Compute a_k: d x 1 summing over columns\n",
    "        a = 2.0*np.asarray((X.power(2).sum(axis=0).T))\n",
    "        c = np.zeros(d)\n",
    "         \n",
    "        for k in range(0,d):\n",
    "            \n",
    "            alpha = np.zeros((d,d))\n",
    "            np.fill_diagonal(alpha, 1)\n",
    "            alpha[k,k] = 0\n",
    "            alpha = X.dot(alpha.dot(w_pred)) + w_0\n",
    "            \n",
    "            #Compute c: d x 1\n",
    "            c[k] = 2.0*X[:,k].T.dot((y-alpha))\n",
    "            \n",
    "            \"\"\"\n",
    "            #Compute c_k: d x 1\n",
    "            c_sum = 0.0\n",
    "            for i in range(0,N):\n",
    "                #Select not k columns\n",
    "                ind = [x for x in range(0,d) if x != k]\n",
    "                c_sum += X[i,k]*(y[i] - (X[i,ind].dot(w_pred[ind]) + w_0))\n",
    "            c[k] = 2.0*c_sum\n",
    "            \"\"\"\n",
    "            \n",
    "            #Compute w_k\n",
    "            if(c[k] < -l):\n",
    "                w_pred[k] = (c[k] + l)/a[k]\n",
    "            elif(c[k] >= -l and c[k] <= l):\n",
    "                w_pred[k] = 0.0\n",
    "            elif(c[k]  > l):\n",
    "                w_pred[k] = (c[k] - l)/a[k]\n",
    "            else:\n",
    "                print \"Error! Shouldn't ever happen.\"\n",
    "        #end for\n",
    "        #print w_pred\n",
    "    #end while\n",
    "    \n",
    "    #Return as row array\n",
    "    return w_pred.T, w_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def lasso_reg_path(X,y,w=-999,w_0=-999,scale=0.8,reg_type=\"naive\"):\n",
    "    \"\"\"\n",
    "    Implimentation of the naive (un-optimized) lasso regression \n",
    "    algorithm.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : n x d matrix of data\n",
    "    y : n x 1 vector of response variables\n",
    "    w : d dimensions weight vector (optional)\n",
    "    w_0 : scalar offset term (optional)\n",
    "    scale : by how much lambda l decreases each run\n",
    "    reg_type : str\n",
    "        naive = use slow naive lasso\n",
    "        quick = use optimized lasso\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    All matrices assumed to be sparse and of the form given by \n",
    "    scipy.sparse.csc matrix\n",
    "    \n",
    "    \"\"\"\n",
    "    #Choose upper bound for lambda, initial conditions\n",
    "    l = compute_max_lambda(X,y)*scale\n",
    "    \n",
    "    #If no initial conditions, assume Gaussian\n",
    "    if w == -999:\n",
    "        w = np.random.randn(d)\n",
    "    if w_0 == -999:\n",
    "        w_0 = np.random.randn(1)\n",
    "    \n",
    "    w_pred = np.copy(w)\n",
    "    w_0_pred = w_0\n",
    "        \n",
    "    #If solution isn't converged, keep going\n",
    "    while(l > 1):\n",
    "        w_pred, w_0_pred = naive_lasso(X,y,l=l,w=w_pred,w_0=w_0_pred)        \n",
    "        \n",
    "        #If solution is sufficiently good, return it\n",
    "        if check_solution(X,y,w_pred=w_pred,w_0_pred=w_0_pred,l=l):\n",
    "            return w_pred, w_0_pred, l\n",
    "        \n",
    "        #Decrease scale for next iteration\n",
    "        l *= scale\n",
    "    \n",
    "    return w_pred, w_0_pred, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def quick_lasso(X,y,l=10,w=-999,w_0=-999):\n",
    "    \"\"\"\n",
    "    Implimentation of the naive (un-optimized) lasso regression \n",
    "    algorithm.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : n x d matrix of data\n",
    "    X_i : the ith row of X\n",
    "    y : N x 1 vector of response variables\n",
    "    w : d dimensions weight vector (optional)\n",
    "    w_0 : scalar offset term (optional)\n",
    "    l : regularization tuning parameter\n",
    "    \n",
    "    All matrices X assumed to be sparse and of the form given by \n",
    "    scipy.sparse.csc matrix\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    w : numpy array\n",
    "        d x 1 weight vector\n",
    "    w_0 : float\n",
    "        offset   \n",
    "    \"\"\"\n",
    "    #Define values\n",
    "    n = y.shape[0]\n",
    "    d = X.shape[1]\n",
    "    \n",
    "    #Convergence condition\n",
    "    eps = 1.0e-5\n",
    "    \n",
    "    #If no initial conditions, assume Gaussian\n",
    "    if w == -999:\n",
    "        w = np.random.randn(d)\n",
    "    if w_0 == -999:\n",
    "        w_0 = np.random.randn(1)\n",
    "    \n",
    "    w_pred = np.copy(w).reshape(d,1) # d x 1\n",
    "    w_old = np.zeros(w_pred.shape) # d x 1\n",
    "    y = y.reshape(n,1) # n x 1\n",
    "    c = np.zeros(d).reshape(d,1)\n",
    "    a = np.zeros(d).reshape(d,1)\n",
    "    \n",
    "    while((w_pred - w_old).dot((w_pred - w_old).T)[0][0] > eps):\n",
    "        if np.fabs(w_0) > 1.0e10:\n",
    "            print(\"w_0 too large\")\n",
    "            break\n",
    "        \n",
    "        #Store for convergence test \n",
    "        w_old = np.copy(w_pred)\n",
    "        \n",
    "        #Compute y_hat (n x 1) to avoid numerical drift\n",
    "        y_hat = X.dot(w_pred) + w_0        \n",
    "            \n",
    "        #Compute w_0 via rule from 6.1.1\n",
    "        w_0 = np.sum(y - np.sum(y_hat))/(n*(1-n))\n",
    "        \n",
    "        #Update y_hat via 6.1.5\n",
    "        y_hat = X.dot(w_pred) + w_0\n",
    "            \n",
    "        #Compute a_k: d x 1 summing over columns\n",
    "        a = 2.0*np.asarray((X.power(2).sum(axis=0).T))\n",
    "          \n",
    "        for k in range(0,d):\n",
    "    \n",
    "            alpha = np.zeros((d,d))\n",
    "            np.fill_diagonal(alpha, 1)\n",
    "            alpha[k,k] = 0\n",
    "            alpha = X.dot(alpha.dot(w_old)) + w_0\n",
    "                \n",
    "            #Compute c: d x 1\n",
    "            c[k] = 2.0*X[:,k].T.dot((y-alpha))\n",
    "            \"\"\"\n",
    "            #Slooooow way\n",
    "            c_sum = 0.0\n",
    "            for i in range(0,N):\n",
    "                #Select not k columns\n",
    "                ind = [x for x in range(0,d) if x != k]\n",
    "                c_sum += X[i,k]*(y[i] - (X[i,ind].dot(w_pred[ind]) + w_0))\n",
    "            c[k] = 2.0*c_sum \n",
    "            \"\"\"\n",
    "            \n",
    "            #Compute w_k\n",
    "            if(c[k] < -l):\n",
    "                w_pred[k] = (c[k] + l)/a[k]\n",
    "            elif(c[k] >= -l and c[k] <= l):\n",
    "                w_pred[k] = 0.0\n",
    "            elif(c[k]  > l):\n",
    "                w_pred[k] = (c[k] - l)/a[k]\n",
    "            else:\n",
    "                print \"Error! Shouldn't ever happen.\"\n",
    "                break\n",
    "            \n",
    "            y_hat = ((X).dot(w_pred)) + alpha\n",
    "        #end for\n",
    "    #end while\n",
    "    \n",
    "    #Return as row array\n",
    "    return w_pred.T, w_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.  10.  10.  10.  10.  10.  10.  10.  10.  10.  10.  10. -10. -10. -10.\n",
      " -10. -10. -10. -10. -10. -10. -10. -10. -10. -10. -10.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "[[ -3.52878053e-01   9.89766898e+00   1.04579078e+01   1.07598058e+01\n",
      "    8.40048951e+00   1.02503609e+01   1.00190667e+01   1.08987968e+01\n",
      "    9.36338436e+00   1.02457505e+01   9.84216693e+00   9.75659587e+00\n",
      "   -1.11147635e+01  -1.01360440e+01  -9.70143207e+00  -9.81376953e+00\n",
      "   -1.01141365e+01  -9.85198189e+00  -9.53002569e+00  -1.04599372e+01\n",
      "   -1.05044987e+01  -9.77258647e+00  -1.01905235e+01  -1.03590558e+01\n",
      "   -9.44997693e+00  -9.10074998e+00   0.00000000e+00   1.06378987e+00\n",
      "   -3.58586165e-01   6.08313447e-01  -5.65625507e-01  -4.35800122e-01\n",
      "    7.81470187e-02  -1.56877156e-02   2.96960798e-02   0.00000000e+00\n",
      "    7.66261642e-01  -8.65111314e-02  -6.56078714e-02   3.95470819e-01\n",
      "   -8.71670714e-02  -4.76747186e-01  -1.98519665e-01  -3.25021210e-01\n",
      "    0.00000000e+00   2.24671178e-01  -2.48890740e-01   3.02367403e-01\n",
      "   -3.81646423e-01  -2.65710037e-01   3.90497176e-01   4.11762847e-02\n",
      "    4.92394523e-01   7.40834770e-01  -1.18332931e-01  -7.28794816e-01\n",
      "   -5.31958712e-01  -5.36049476e-02  -3.49200589e-01  -4.26934943e-01\n",
      "   -4.80372826e-01   4.57892011e-01   2.54521448e-01   1.28487934e+00\n",
      "    1.94495982e-01   9.42442538e-01   2.16158274e-01   2.92437056e-01\n",
      "   -2.98891156e-01  -1.02562928e-01  -1.14593298e-01   7.49436246e-01\n",
      "    5.72949408e-02   4.14564081e-01   4.39879790e-01   2.08218818e-02\n",
      "    6.02661884e-01  -4.76560717e-01  -3.96904755e-01   5.59873758e-01\n",
      "   -3.59760898e-02   2.60838403e-02  -7.38673483e-01   2.45667567e-01\n",
      "   -9.97001246e-02   2.31668122e-01  -8.33571394e-01  -6.07166549e-01\n",
      "   -1.46001427e-01   0.00000000e+00  -7.24637395e-01   2.02202659e-01\n",
      "    2.77895026e-01  -8.40792588e-01   7.51362048e-01  -5.46026117e-02\n",
      "   -3.82898269e-01   3.74302625e-01   2.03056701e-01  -3.83666056e-01\n",
      "    3.49898315e-01  -1.55987654e-01   8.95085785e-02   1.03794598e-02\n",
      "   -8.67657644e-01  -2.28603397e-01   1.70424878e-01   3.23239934e-01\n",
      "   -6.84633320e-02   3.00828490e-01  -7.69944586e-02   1.01419485e-01\n",
      "    8.97620878e-02  -9.17976710e-03   4.63880714e-01   2.67531526e-01\n",
      "   -3.21399799e-01  -2.07464937e-01   1.27998128e-01  -8.04793127e-01\n",
      "    0.00000000e+00   1.42053078e-01   6.75549205e-02  -1.32739270e-01\n",
      "   -4.20478250e-01  -3.47221113e-01  -7.54935175e-02   3.11856076e-01\n",
      "   -5.37711592e-01  -1.33206664e-01   0.00000000e+00   1.84116320e-01\n",
      "   -5.40213856e-01   6.41524722e-02   1.88170679e-01  -3.53532063e-01\n",
      "    1.62715552e-01  -8.02694451e-01   2.32480499e-02   1.67269641e-01\n",
      "   -4.39828305e-01  -3.02654045e-02  -5.22930818e-01   9.71379157e-01\n",
      "    3.44087529e-01   3.61173772e-01   2.99282675e-01  -4.37279191e-01\n",
      "   -7.93960708e-01   0.00000000e+00   1.81444577e-01   9.87681827e-02\n",
      "    2.70633916e-01  -7.91744946e-01   3.51247938e-01   2.10569952e-01\n",
      "   -1.03063305e+00   5.71964128e-02   5.76612910e-01   2.05684218e-01\n",
      "   -2.90234605e-01   2.20208323e-01   3.71850204e-01   1.53008096e-01\n",
      "   -1.41906325e-01   2.88050776e-01   1.46530414e-01   1.70749891e-01\n",
      "   -2.07228067e-01   6.23896460e-01   0.00000000e+00  -2.71625508e-01\n",
      "    3.75159744e-01   2.81104650e-01   4.35390500e-02  -1.20371289e-01\n",
      "   -3.23298446e-02   1.72778163e-01   1.37263026e-01  -6.63437953e-01\n",
      "    0.00000000e+00  -1.84988379e-01   4.17612674e-01   3.13837769e-01\n",
      "   -1.68453010e-01  -7.16663047e-01   6.86010162e-01  -3.23299980e-01\n",
      "   -1.36877308e-01  -8.49433141e-01   1.89661230e-01  -2.09113739e-01\n",
      "    2.87272906e-01   8.93135790e-02   5.73160048e-02  -7.51469134e-01\n",
      "   -2.14006597e-01  -1.16231193e-01   2.55924765e-01   4.67855227e-01\n",
      "   -4.41304486e-01   0.00000000e+00  -4.02600199e-01  -4.04530491e-01\n",
      "    0.00000000e+00  -1.52870500e-02  -6.20070743e-01  -1.10269152e-01\n",
      "   -1.40532525e-01  -3.73945983e-01   4.44887466e-01  -4.65518143e-01\n",
      "   -1.71919109e-01   3.53619246e-01  -3.65486108e-02   5.62175686e-02\n",
      "   -1.02462457e-01  -5.92532695e-02  -8.03831700e-01   4.22165139e-01\n",
      "   -7.76306969e-01   1.29106716e-03   4.98450563e-01   4.94593991e-01\n",
      "    7.41814935e-02   2.54902635e-01   1.10371715e-01  -1.64072452e-01\n",
      "   -4.62738604e-01   6.39864607e-01  -1.01528902e-01   8.58951857e-02\n",
      "    3.76664636e-01  -4.66240043e-01   6.68658578e-02   2.24892978e-02\n",
      "   -3.27096921e-01  -8.52653588e-02  -5.38176039e-01   1.51824016e-01\n",
      "    0.00000000e+00  -1.52328223e-01   2.37524015e-02  -7.69689377e-01\n",
      "    2.82327374e-01  -2.57388751e-01   3.48568605e-01  -1.08463176e-01\n",
      "    8.99678094e-02  -1.54526780e-01   5.11863702e-01   2.23178717e-01\n",
      "    3.59826573e-01  -7.27502177e-02   3.24430504e-01   4.06015264e-01\n",
      "   -1.08464622e+00   9.93496286e-01  -5.89988944e-01   7.69828167e-01\n",
      "    2.29369931e-01  -8.65783483e-02  -1.66208342e-02  -3.78517469e-01\n",
      "   -2.84438356e-02  -2.05275516e-02   1.14350453e-01  -3.13686515e-01\n",
      "    1.56957920e-01   3.07457925e-02  -7.69305767e-02  -2.72128303e-01\n",
      "   -1.85764970e-02  -5.80145310e-02   8.81279218e-03   2.00495205e-01\n",
      "   -1.15393530e-02   0.00000000e+00  -1.18303576e-01   2.73517873e-01\n",
      "   -4.57954479e-01   1.23166146e-02  -1.51179874e-01   2.80418112e-01\n",
      "   -6.14613226e-01  -3.39129946e-01  -3.13839813e-01   2.53412530e-01\n",
      "   -1.85154272e-01  -3.29786017e-01   1.83122890e-01   9.94500813e-02\n",
      "   -8.41091425e-01   1.04553652e+00  -8.61611961e-02   4.21832627e-01\n",
      "    5.21486703e-01   1.34666568e-01   7.57684194e-01   5.95755072e-02\n",
      "   -7.89980643e-01   4.27028401e-01   1.88707646e-02   3.77397015e-01\n",
      "   -3.80218869e-01   0.00000000e+00  -7.62752923e-01  -9.75159411e-02\n",
      "   -6.77120469e-01  -8.38539531e-01  -2.86630331e-01  -2.19230217e-01\n",
      "    2.88200961e-01   8.74496328e-02  -1.35425050e-01  -6.26309584e-01\n",
      "   -2.99921629e-02  -3.80531653e-02   6.38240710e-01  -1.62699307e-01\n",
      "    1.95275275e-01  -2.57687652e-01   5.78388313e-02  -7.03295580e-03\n",
      "    9.10792881e-01   5.54670414e-01  -3.50823774e-01  -2.37421614e-01\n",
      "   -1.65537483e-01   1.22951340e-01   7.77124742e-01  -1.04465852e-01\n",
      "   -1.65652061e-01   1.41106139e-01  -2.43945619e-02  -4.61425122e-01\n",
      "   -3.57756220e-01  -6.44458479e-03  -3.32235299e-01  -1.87166362e-01\n",
      "    0.00000000e+00   9.73859754e-01   3.83795539e-01  -2.23440004e-01\n",
      "   -7.38479863e-01   0.00000000e+00   2.03591350e-02   5.68893257e-01\n",
      "   -5.50626112e-02  -3.57713790e-01   7.08566020e-02  -2.98936018e-01\n",
      "   -3.18140288e-01   1.74825985e-01  -4.37912725e-01  -7.04983657e-01\n",
      "    5.50589615e-01  -1.26699381e-01  -3.52013849e-01  -3.24301737e-01\n",
      "    6.25719190e-01   4.49897603e-01   6.77086737e-01  -2.10438174e-02\n",
      "   -1.49648428e-01  -3.43603323e-01   0.00000000e+00   1.52792534e-01\n",
      "   -5.59441336e-02  -5.06893556e-02   0.00000000e+00   1.30794938e-01\n",
      "   -3.74878134e-01   2.09719878e-02   4.27924973e-01   2.88264366e-01\n",
      "   -1.37805031e-01   3.83790278e-01  -7.35809113e-02   3.14682729e-01\n",
      "    1.95792019e-01  -3.35637204e-01  -5.21527869e-02   5.00529397e-01\n",
      "    7.73074183e-01  -4.46364322e-01   1.76894049e-01   7.01272491e-02\n",
      "   -8.32735744e-01   5.05959936e-02   1.85248090e-01  -6.29831538e-01\n",
      "   -5.05548387e-02  -5.14160048e-02   4.79260265e-01  -4.03063918e-01\n",
      "    8.54868085e-01   5.29088702e-01  -6.14121864e-03  -1.75671678e-01\n",
      "    2.35279375e-01   2.58143983e-01   4.94506299e-01   2.07173175e-01\n",
      "    3.86522306e-01  -1.58640553e-01   2.18091215e-01  -7.24684771e-02\n",
      "    1.24867393e-01  -6.10210424e-01  -4.56155287e-01   2.88009133e-02\n",
      "    3.50029487e-01   2.01500365e-01   1.41022439e-02  -1.18635856e-03\n",
      "   -2.56109294e-02   0.00000000e+00  -4.59416358e-02  -4.83312222e-01\n",
      "    0.00000000e+00  -1.38205146e-01   4.37802847e-01   4.95951127e-01\n",
      "    9.32152988e-03   6.22615415e-02   4.19000122e-01  -1.61936473e-01\n",
      "    3.71718341e-01   2.58191628e-01   3.75174740e-01  -1.42148405e-01\n",
      "    0.00000000e+00  -2.58381799e-01  -3.79535295e-01   3.36476597e-01\n",
      "   -4.51643555e-02   4.18088905e-01   4.80889236e-01   1.21650724e-01\n",
      "   -4.21617072e-01  -3.44572571e-02  -1.22107770e-01  -1.21287429e-01\n",
      "    8.60712938e-01   1.95104823e-01   7.91101843e-01  -2.42029059e-01\n",
      "   -1.84528168e-01   7.55782383e-01  -3.59803905e-01  -1.75074821e-01\n",
      "    1.55973532e-01   3.71441054e-01  -1.32144429e-01   3.22827888e-01\n",
      "    2.09683856e-01  -1.05344847e-01   2.49859309e-01   2.40711270e-01\n",
      "    7.98656404e-02   1.81340809e-02  -6.35688863e-02  -2.28140341e-01\n",
      "   -4.23583738e-01   3.53870253e-01  -3.00766118e-01  -2.66684970e-01\n",
      "    5.07436899e-01  -5.50446511e-04  -2.27223451e-02   6.67241393e-01\n",
      "    3.74577105e-01   8.97192358e-02   2.16759430e-01  -2.34191210e-01\n",
      "   -3.22843775e-02   1.00251060e-01  -4.08194934e-01   0.00000000e+00\n",
      "    2.39822452e-01  -4.20534915e-01   2.12395677e-01  -1.00894908e-01\n",
      "    2.41140168e-01  -7.58707258e-01   1.05536880e-01   4.86162644e-01\n",
      "    0.00000000e+00   6.78840428e-01   2.67881371e-01   7.11997842e-01\n",
      "   -5.79384365e-01   4.75421823e-01   0.00000000e+00   4.69799251e-03\n",
      "    3.79888216e-01  -4.26716460e-01  -4.54174963e-01   7.17449372e-02\n",
      "    1.43612656e-01   1.82306121e-01  -5.61276704e-01   0.00000000e+00\n",
      "    0.00000000e+00  -9.70804169e-02  -1.55485017e-01  -4.81442582e-01\n",
      "    1.25106754e-01   5.58697675e-01  -1.15040837e-02   5.18736616e-02\n",
      "   -2.37397706e-02  -4.90864563e-01   7.06525559e-01  -3.85514388e-01\n",
      "    4.14014728e-01  -8.27413092e-02   4.94313281e-01  -5.37537545e-01\n",
      "    4.10505340e-01  -1.41451558e-02   3.35629753e-01  -1.83232561e-01\n",
      "    3.29819144e-01   5.27420801e-02   3.18114086e-01   4.79794179e-01\n",
      "    5.55534504e-03  -1.56899836e-01   0.00000000e+00   2.36311851e-02\n",
      "    1.25756553e-01  -1.26958322e-01  -9.08997502e-03  -2.62514346e-01\n",
      "   -5.71977668e-01  -2.48273920e-01   2.09996772e-01  -3.91855383e-01\n",
      "    4.98119969e-01   2.84497406e-01  -3.28399958e-01   4.19910062e-01\n",
      "    7.35479918e-01   4.02870691e-01   0.00000000e+00   1.49145331e-01\n",
      "    4.06611015e-01   1.23424105e-01   3.17159497e-01   3.69300714e-01\n",
      "    4.65943055e-01  -7.26686057e-02   0.00000000e+00   3.46813236e-01\n",
      "   -1.17859316e-01   0.00000000e+00   2.19919368e-01   1.79381085e-01\n",
      "    4.62939856e-01   5.44526943e-02   1.10487480e-01   7.30097671e-02\n",
      "   -1.75486333e-01   4.81461501e-01  -4.32629942e-01   1.00479124e-01\n",
      "    1.02720190e-01   5.23594840e-02   7.86797321e-01   9.10946216e-01\n",
      "    5.85638363e-01   4.89457758e-01  -2.52281328e-01   1.01614772e-02\n",
      "   -1.76218422e-01   8.11542197e-02  -4.12810595e-01  -8.88112899e-01\n",
      "   -1.46856346e-01   1.38540609e-01   3.99234969e-01  -1.83978600e-01\n",
      "    6.18065960e-01  -4.52809370e-02  -3.66456641e-01  -4.46155895e-01\n",
      "    5.90020035e-03  -3.42738775e-01   3.80416048e-01  -3.72685291e-01\n",
      "   -1.75776450e-01  -7.74904645e-01   1.06996227e+00   5.16844844e-02\n",
      "   -7.75398646e-02   1.38670135e-01   6.40878358e-01  -8.05386987e-02\n",
      "    2.20700712e-01   2.29853628e-01   7.80430448e-02  -3.00232362e-01\n",
      "    1.25808381e-01  -4.25611713e-01   2.14055257e-01  -3.41551129e-01\n",
      "   -1.94278724e-01  -2.44137838e-01  -4.79226880e-01  -5.42642232e-01\n",
      "    2.04929045e-01   2.58361461e-01  -9.66354735e-01   2.92160044e-01\n",
      "   -1.67196192e-02  -6.70091358e-03  -1.96222616e-01  -1.59921440e-01\n",
      "   -5.90838382e-01   3.10904544e-02  -3.75689093e-01  -3.98785199e-02\n",
      "   -2.39961570e-02  -4.35452457e-01  -5.59553193e-01  -1.07305863e-01\n",
      "   -1.33195902e-01   3.28158714e-01  -4.51970001e-02   3.37383411e-01\n",
      "    5.98741826e-01   7.23254878e-02   1.49379705e-01  -7.77203502e-03\n",
      "    2.18292887e-01   1.50971917e-01  -2.23726000e-01  -4.16183842e-01\n",
      "    0.00000000e+00   1.38770819e-01   1.77880162e-03  -8.23753660e-01\n",
      "    5.39719844e-02   8.89861847e-02   3.62243141e-01   2.33140119e-02\n",
      "    8.35165674e-02  -2.23891775e-01   1.44294944e-02   4.90349437e-01\n",
      "    6.36444514e-01  -4.19628616e-01   8.13266556e-01   3.39966932e-02\n",
      "   -1.25801716e-01   1.32207250e-01  -9.82170925e-01   2.97562987e-02\n",
      "    5.72566602e-02   9.76315774e-02  -1.01046200e-01  -8.06061256e-01\n",
      "    1.60322311e-01   2.78778318e-01   2.77198026e-01   3.92860360e-01\n",
      "   -3.74936238e-01  -8.38467510e-02  -4.29442541e-01   6.15316968e-02\n",
      "   -4.09440028e-01   5.64782633e-01  -9.05042227e-02   9.25932980e-02\n",
      "   -2.33847862e-01   4.20103890e-01   1.76294360e-01   1.71400762e-02\n",
      "   -1.61157110e-02  -2.34020774e-01   2.93165623e-01  -1.80251637e-01\n",
      "   -2.75682841e-03  -4.70956513e-01  -2.34301327e-01  -8.45912974e-02\n",
      "   -3.25565201e-01  -7.59809787e-01   6.01111363e-01   0.00000000e+00\n",
      "    2.87952577e-01   3.46247753e-01  -4.00059420e-01   0.00000000e+00\n",
      "   -3.98710027e-01   2.42907475e-01   5.74577711e-01   0.00000000e+00\n",
      "    6.88878061e-01   1.47758313e-01  -1.99553669e-01   1.70425996e-01\n",
      "    9.28780261e-02  -2.11262268e-01  -2.48786162e-01  -3.79038014e-01\n",
      "   -1.57693857e-01  -8.68671533e-02   5.98634361e-01  -4.49724661e-01\n",
      "   -8.24129220e-02  -2.39656473e-02   5.52877001e-02  -4.81571123e-02\n",
      "    1.23428527e-01  -5.36750667e-01  -7.33391997e-02  -3.60105332e-01\n",
      "   -3.03947161e-01   5.04940834e-02   8.46528610e-01   2.36866607e-01\n",
      "   -1.39036252e-01  -3.73335473e-01   2.43190175e-01   1.06233449e-01\n",
      "   -3.83255897e-01   1.35764776e-01  -5.09654920e-01  -2.22512837e-02\n",
      "    5.34643673e-01   2.42325835e-01   1.00791431e+00  -5.13453725e-02\n",
      "    1.73940391e-01   4.21646861e-01   1.08482576e-01   3.63397399e-02\n",
      "    5.46412501e-01  -1.41760331e-01   4.02376235e-01  -2.08240518e-01\n",
      "   -1.02444556e-01   5.88080323e-01  -4.90687634e-01  -5.51795771e-01\n",
      "   -3.11753136e-01   5.14456509e-01  -6.34792396e-02  -2.14488333e-02\n",
      "   -4.82403157e-01   6.09544611e-02  -1.69541945e-01   0.00000000e+00\n",
      "    0.00000000e+00   1.83604827e-01   2.96448430e-04   8.38244442e-01\n",
      "    7.92807998e-01  -7.17339705e-01   2.58578099e-01  -1.67981351e-01\n",
      "    2.48436378e-01  -1.61135165e-01   0.00000000e+00   3.36307443e-01\n",
      "    8.10881307e-01  -4.10847895e-01  -2.22780728e-02   3.14779840e-01\n",
      "    4.19131305e-01  -5.95320161e-01  -7.36813414e-02   1.61663686e-01\n",
      "    2.62134617e-01  -8.28144440e-02  -2.08123991e-01   1.28212119e-01\n",
      "   -8.76213761e-02   3.24559954e-01  -2.84053861e-02   2.95647268e-01\n",
      "    3.00693971e-01  -1.56263305e-01   4.01164501e-01   4.74486398e-01\n",
      "    5.68347333e-02  -5.85168089e-01  -4.71519003e-01  -1.07834391e-01\n",
      "    3.77464253e-02  -1.70403677e-01   2.97291081e-01   7.82877364e-02\n",
      "   -3.41170933e-02   1.07366074e-01   1.06117732e-01   6.45077931e-02\n",
      "    4.26072198e-01   1.02682006e-01  -9.11580076e-01  -2.80648899e-01\n",
      "   -1.22606912e-01   2.32701585e-03   2.57018484e-01  -3.23140248e-01\n",
      "   -3.52812316e-01   9.60146971e-02   1.35581065e-01  -1.75150200e-01\n",
      "    1.55738274e-01  -1.55916675e-01  -3.32085729e-02  -3.70409300e-03\n",
      "   -1.32330191e-01  -1.79705978e-01   6.65425406e-02  -6.29351351e-01\n",
      "    5.33459230e-01  -3.16961418e-01   1.65869453e-02  -9.57503451e-02\n",
      "   -3.95976814e-01   3.30927093e-01   3.82572470e-01   8.06642129e-02\n",
      "    1.49588895e-01  -4.46024102e-01  -1.82583643e-01   4.21751892e-01\n",
      "    3.21526340e-01   8.57458476e-01  -2.97907999e-01  -3.63490690e-01\n",
      "    1.01705092e-01  -2.34931451e-01  -3.61935389e-01   5.22104627e-02\n",
      "    0.00000000e+00  -1.01304767e+00   0.00000000e+00   3.54222609e-01\n",
      "    5.34723533e-01  -3.22818177e-01  -1.18663293e-02   1.37406903e-01\n",
      "    4.14504479e-01  -2.15275548e-01  -2.55143763e-01   3.37904785e-02\n",
      "    4.49777351e-01  -6.36864395e-01  -1.05227159e-01   1.73656079e-01\n",
      "   -5.08858859e-02   1.38772623e-02   0.00000000e+00   2.36400455e-01\n",
      "    3.76274928e-01  -7.32686635e-01   5.37676480e-01   9.38591991e-02\n",
      "    4.66859101e-01   1.33280631e-01  -3.42205851e-01  -4.21166719e-01\n",
      "   -6.29841292e-01  -2.09721548e-02   6.61486028e-01   2.38461998e-01\n",
      "    9.00625599e-01   1.76253584e-01   0.00000000e+00   0.00000000e+00\n",
      "   -2.91163405e-01  -1.90001650e-01   5.02089215e-02  -1.92470987e-01\n",
      "    0.00000000e+00  -4.05542320e-02   2.29917697e-01   0.00000000e+00\n",
      "   -2.53674126e-01  -3.01573489e-01  -5.24538118e-01   0.00000000e+00\n",
      "   -9.03033188e-02  -1.07265482e-02  -3.41777250e-03  -1.99418471e-01\n",
      "   -5.15059362e-01  -5.75302054e-01   2.01550491e-01   3.52273388e-01\n",
      "    3.23091715e-01  -3.21902957e-01  -2.19483398e-01   6.20347837e-01\n",
      "   -3.10143754e-01  -1.00193301e-02  -4.96902592e-01  -5.92964151e-02\n",
      "    2.47705754e-01   0.00000000e+00   9.06045178e-01   6.91135649e-01\n",
      "    2.29654064e-02  -8.86423535e-03   3.98800458e-01  -2.15941984e-03\n",
      "    6.35606739e-02  -1.08410169e-01  -6.10264472e-01  -1.14832998e-01\n",
      "   -3.01621924e-01   3.62104498e-01   3.92831356e-01   1.59804920e-01\n",
      "   -1.77706769e-01  -2.73181503e-01   5.80391941e-01   2.65712556e-01\n",
      "    1.58935826e-02  -5.40163990e-01   1.15321214e+00   6.31977128e-01\n",
      "   -6.65899352e-02  -4.34205738e-01   5.23896448e-03  -2.60112859e-02\n",
      "   -2.21047963e-01  -2.03969773e-01   3.11523445e-01  -5.34951994e-01\n",
      "    2.08917693e-01  -2.30660949e-01  -3.69255399e-02   3.20727363e-01\n",
      "    2.08421640e-01   1.52416125e-01  -7.05648635e-01   8.38403094e-02\n",
      "    3.97066892e-01   4.13541211e-01  -6.12024318e-01   5.64606452e-01\n",
      "   -2.58992875e-02  -8.57862864e-01  -1.06897381e+00  -3.06886197e-01\n",
      "    8.31871550e-02   3.05252075e-01   6.30128741e-01   0.00000000e+00\n",
      "   -2.51207634e-01  -6.96752295e-01   1.97488193e-01  -1.26204212e-01\n",
      "   -6.91232311e-01  -4.70757863e-01   8.11086282e-02  -4.59299524e-01\n",
      "    3.96211443e-01   3.26075748e-01  -6.15658751e-01   6.46966414e-01\n",
      "   -3.67491606e-01   3.09933750e-02   3.03182871e-01   2.56491285e-01\n",
      "   -9.32324951e-01  -7.74483823e-02  -4.56148054e-02  -3.13874214e-01\n",
      "    0.00000000e+00   1.56269919e-01  -1.50955262e-01   2.56080394e-01\n",
      "    7.20411276e-02  -7.69873668e-02   3.65410349e-02   3.19071690e-02\n",
      "    2.57832519e-01  -3.62103879e-01  -2.99251151e-01  -6.28948789e-02\n",
      "    3.06484038e-02  -4.87185539e-01  -6.59083560e-02   2.83367507e-01\n",
      "   -1.41149160e-01  -2.31695307e-01   5.18832031e-01   1.07089201e-01\n",
      "    1.68873641e-01  -1.05876370e-01  -4.77111635e-02   4.90447330e-01]]\n",
      "\n",
      "0.945144730615\n",
      "1 loops, best of 1: 25.1 s per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1 -r1\n",
    "N = 1000\n",
    "k = 25\n",
    "d = 1000\n",
    "w, X, y = generate_norm_data(N,k,d)\n",
    "\n",
    "w_pred, w_0_pred = naive_lasso(X,y,l=40)\n",
    "\n",
    "#print w\n",
    "#print w_pred\n",
    "#print l\n",
    "print\n",
    "\n",
    "SSres = np.sum(np.power(w_pred-w,2))\n",
    "w_bar = np.mean(w)\n",
    "SStot = np.sum(np.power(w_pred-w_bar,2))\n",
    "print(1.0 - (SSres/SStot))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "N = 50\n",
    "k = 5\n",
    "d = 75\n",
    "#l = 2750\n",
    "w, X, y = generate_norm_data(N,k,d)\n",
    "\n",
    "#print(w.shape)\n",
    "#print\n",
    "#print(X.shape)\n",
    "#print\n",
    "#print(y.shape)\n",
    "\n",
    "l = compute_max_lambda(X,y)\n",
    "\n",
    "print\n",
    "print l\n",
    "print\n",
    "\n",
    "w_pred, w_0_pred = naive_lasso(X,y,l=40)\n",
    "#w_test = -999\n",
    "#w_0_test = -999\n",
    "#w_pred, w_0_pred, l = lasso_reg_path(X,y,w=w_test,w_0=w_0_test,scale=0.9,reg_type=\"naive\")\n",
    "\n",
    "#print w\n",
    "print w\n",
    "print w_pred\n",
    "print\n",
    "\n",
    "SSres = np.sum(np.power(w_pred-w,2))\n",
    "w_bar = np.mean(w)\n",
    "SStot = np.sum(np.power(w_pred-w_bar,2))\n",
    "print(1.0 - (SSres/SStot))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import scipy.io as io\n",
    "import scipy.sparse as sparse\n",
    "import os\n",
    "\n",
    "os.chdir(\"/Users/dflemin3/Desktop/CSE_546/HW1/hw1-data\")\n",
    "\n",
    "# Load a text file of integers:\n",
    "y = np.loadtxt(\"upvote_labels.txt\", dtype=np.int)\n",
    "\n",
    "# Load a text file of strings:\n",
    "featureNames = open(\"upvote_features.txt\").read().splitlines()\n",
    "\n",
    "# Load a csv of floats:\n",
    "A = np.genfromtxt(\"upvote_data.csv\", delimiter=\",\")\n",
    "\n",
    "# Load a matrix market matrix, convert it to csc format:\n",
    "#B = io.mmread(\"star_data.mtx\").tocsc()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "A = sparse.csc_matrix(A)\n",
    "print A.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "w_pred, w_0_pred = naive_lasso(X=A[:3000,:],y=y[:3000],w=-999,w_0=-999,l=10000)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#print w_pred\n",
    "print w_0_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 1)\n"
     ]
    }
   ],
   "source": [
    "alpha = np.zeros((d,d))\n",
    "np.fill_diagonal(alpha, 1)\n",
    "alpha[k,k] = 0\n",
    "alpha = X.dot(alpha.dot(w_pred.T))\n",
    "print alpha.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -3.98862838e+10] [ -3.98862838e+10]\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "tmp = 0.0\n",
    "for j in range(0,d):\n",
    "    if j != k:\n",
    "        tmp += X[i,j]*w_pred.T[j]\n",
    "        \n",
    "print tmp, alpha[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -3.98862838e+10]]\n"
     ]
    }
   ],
   "source": [
    "ind = [x for x in range(0,d) if x != k]\n",
    "c_sum = X[i,ind].dot(w_pred.T[ind])\n",
    "print c_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c_1 = np.zeros(d).reshape(d,1)\n",
    "c_2 = np.zeros(c_1.shape)\n",
    "\n",
    "\n",
    "y = y.reshape(N,1)\n",
    "\n",
    "w_0 = 1\n",
    "for k in range(0,d):\n",
    "    alpha = np.zeros((d,d))\n",
    "    np.fill_diagonal(alpha, 1)\n",
    "    alpha[k,k] = 0\n",
    "    alpha = X.dot(alpha.dot(w_pred.T)) + w_0\n",
    "        \n",
    "    #Compute c: d x 1\n",
    "    c_1[k] = 2.0*X[:,k].T.dot((y-alpha))\n",
    "    #Slooooow way\n",
    "    c_sum = 0.0\n",
    "    for i in range(0,N):\n",
    "        #Select not k columns\n",
    "        ind = [x for x in range(0,d) if x != k]\n",
    "        c_sum += X[i,k]*(y[i] - (X[i,ind].dot(w_pred.T[ind]) + w_0))\n",
    "    c_2[k] = 2.0*c_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print np.allclose(c_1,c_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
